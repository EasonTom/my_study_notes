# 中间件

中间件是Scrapy里面的一个核心概念。使用中间件可以在爬虫的请求发起之前或者请求返回之后对数据进行定制化修改，从而开发出适应不同情况的爬虫。

## 1 下载中间件

下载器中间件是介于Scrapy的request/response处理的钩子框架，是用于全局修改Scrapy request和response的一个轻量、底层的系统。

这个介绍看起来非常绕口，但其实用容易理解的话表述就是：更换代理IP，更换Cookies，更换User-Agent，自动重试。



### 1.1 激活下载器中间件

要激活下载器中间件组件，将其加入到 [`DOWNLOADER_MIDDLEWARES`](https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/settings.html#std:setting-DOWNLOADER_MIDDLEWARES) 设置中。 该设置是一个字典(dict)，键为中间件类的路径，值为其中间件的顺序(order)。

这里是一个例子:

```
DOWNLOADER_MIDDLEWARES = {
    'myproject.middlewares.CustomDownloaderMiddleware': 543,
}
```

[`DOWNLOADER_MIDDLEWARES`](https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/settings.html#std:setting-DOWNLOADER_MIDDLEWARES) 设置会与Scrapy定义的 [`DOWNLOADER_MIDDLEWARES_BASE`](https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/settings.html#std:setting-DOWNLOADER_MIDDLEWARES_BASE) 设置合并(但不是覆盖)， 而后根据顺序(order)进行排序，最后得到启用中间件的有序列表: 第一个中间件是最靠近引擎的，最后一个中间件是最靠近下载器的。

关于如何分配中间件的顺序请查看 [`DOWNLOADER_MIDDLEWARES_BASE`](https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/settings.html#std:setting-DOWNLOADER_MIDDLEWARES_BASE) 设置，而后根据您想要放置中间件的位置选择一个值。 由于每个中间件执行不同的动作，您的中间件可能会依赖于之前(或者之后)执行的中间件，因此顺序是很重要的。

如果您想禁止内置的(在 [`DOWNLOADER_MIDDLEWARES_BASE`](https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/settings.html#std:setting-DOWNLOADER_MIDDLEWARES_BASE) 中设置并默认启用的)中间件， 您必须在项目的 [`DOWNLOADER_MIDDLEWARES`](https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/settings.html#std:setting-DOWNLOADER_MIDDLEWARES) 设置中定义该中间件，并将其值赋为 None 或0。 例如，如果您想要关闭user-agent中间件:

```
DOWNLOADER_MIDDLEWARES = {
    'myproject.middlewares.CustomDownloaderMiddleware': 543,
    'scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware': None,
}
```

最后，请注意，有些中间件需要通过特定的设置来启用。更多内容请查看相关中间件文档。

在配置文件`settings.py`中的`DOWNLOADER_MIDDLEWARES`中配置键值对，键为要打开的中间件，值为数字，代表优先级，值越低，优先级越高。

### 1.2 自定义下载中间件

在项目文件夹下的middlewares.py文件下自定义中间件类，名字可以自定义，然后在settings.py文件的DOWNLOADER_MIDDLEWARES中激活。

下载中间件包含有以下方法：

- process_request(request, spider)

当每个Request对象经过下载中间件时会被调用，即下载前调用，**优先级越高的中间件，越先调用；**该方法应该返回以下对象：`None`/`Response`对象/`Request`对象/抛出`IgnoreRequest`异常；

1. 返回`None`：scrapy会继续执行其他中间件相应的方法；
2. 返回`Response`对象：scrapy不会再调用其他中间件的`process_request`方法，也不会去发起下载，而是直接返回该`Response`对象，并原路返回；
3. 返回`Request`对象：scrapy不会再调用其他中间件的`process_request()`方法，而是将其放置调度器待调度下载；
4. 抛出`IgnoreRequest`异常：已安装中间件的`process_exception()`会被调用，如果它们没有捕获该异常，则`Request.errback`会被调用；如果再没被处理，它会被忽略，且不会写进日志。

加代理只需要重写该方法：

```
def process_request(self, request, spider)	
	request.headers['User-Agent'] = useragent # 设置头
	request.meta['proxy'] = 'http://0.0.0.0:00' # 设置代理
	request.cookies={'currency': 'USD', 'country': 'UY'} # 设置cookies
	return None
```

- process_response(request, response, spider)

当每个Response经过下载中间件会被调用，即下载后调用，**优先级越高的中间件，越晚被调用，与process_request()相反；**该方法返回以下对象：`Response`对象/`Request`对象/抛出`IgnoreRequest`异常。

1. 返回`Response`对象：scrapy会继续调用其他中间件的`process_response`方法；
2. 返回`Request`对象：停止中间器调用，将其放置到调度器待调度下载；
3. 抛出`IgnoreRequest`异常：`Request.errback`会被调用来处理函数，如果没有处理，它将会被忽略且不会写进日志。

- process_exception(request, exception, spider)

当`process_exception()`和`process_request()`抛出异常时会被调用，应该返回以下对象：None/`Response`对象/`Request`对象；

1. 如果返回`None`：scrapy会继续调用其他中间件的`process_exception()`；
2. 如果返回`Response`对象：中间件链的`process_response()`开始启动，不会继续调用其他中间件的`process_exception()`；
3. 如果返回`Request`对象：停止中间器的`process_exception()`方法调用，将其放置到调度器待调度下载。

- from_crawler(cls, crawler)

如果存在该函数，`from_crawler`会被调用使用`crawler`来创建中间器对象，必须返回一个中间器对象，通过这种方式，可以访问到`crawler`的所有核心部件，如`settings`、`signals`等。

## 2 爬虫中间件